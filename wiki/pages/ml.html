{% extends "layout.html" %}

{% block title %}ML Modelling{% endblock %}

{% block extra_css %}
<link rel="stylesheet" href="{{ url_for('static', filename='experimentation.css') }}">
{% endblock %}

{% block page_content %}

<div class="docs-layout">
    <aside class="docs-sidebar">
        <nav id="docs-nav" class="w-full"></nav>
    </aside>

    <main class="lg:pl-8">
        <article>
            <header id="top">
                <h1>Machine Learning Predictive Model</h1>
                <p class="lead">Predicting the ammonium concentration in soil using a Machine Learning model</p>
            </header>

            <p class="animate-on-scroll">
                The rich microbial environment of the soil is a very dynamic and complex system – consisting of numerous interactions and factors which affect both the ecosystem and each other, such as pH, oxygen content, nitrate concentration, temperature, ammonium concentration, carbon content, C/N ratio, particle size, soil type, humidity and precipitation, latitude, longitude, etc.
            </p>

            <div class="accordion-container">
                <div class="accordion-item">
                    <button class="accordion-header">
                        <span>Approximations</span>
                        <span class="accordion-icon">+</span>
                    </button>
                    <div class="accordion-content">
                        <p>
                            We approximated the basal Dissimilatory Nitrate Reduction to Ammonium (DNRA) rate based on Michaelis-Menten kinetics, using a gross average of the cell population in a given mass of soil. The increased DNRA rate was estimated using maximum rates from our ODE model.
                        </p>
                        <br>
                    </div>
                </div>
            </div>

            <section id="intro" data-aos="fade-up">
                <h2>Introduction</h2>
                <p class="animate-on-scroll">
                    DNRA in soil is highly interconnected with several soil and environmental factors. Since these factors are very hard to model individually and their individual and bulk effects on the rate of DNRA are very complex, we decided to use Machine Learning to find patterns across bulk data sets from all across the world with different conditions.
                </p>
                <p class="animate-on-scroll">
                    The goal of the model is to predict the ammonium concentration in soil conditions that will occur when we introduce our modified bacterium into the ecosystem.
                </p>
            </section>
            
            <section id="why-ml" data-aos="fade-up">
                <h2>Why Use Machine Learning?</h2>
                
                <h3>What is a Machine Learning Model?</h3>
                <p class="animate-on-scroll">
                    A Machine Learning model is a mathematical representation of a real-world process that is trained on data to make predictions or decisions without being explicitly programmed for the specific task. Essentially, it manipulates data and learns from already known outputs to predict the outputs for inputs we have not seen before. Although a very poor simplification, it can be thought of as a glorified form of curve-fitting.
                </p>
                
                <h3>Why ML?</h3>
                <p class="animate-on-scroll">
                    Although the concept of ML has become a buzzword today, going past the hype, ML models are a great way to predict complex non-linear relationships, like the interplay of factors that influence the soil ecosystem. These are complex environments, with many hundreds of variables affecting the outcome and each other, for which it is very difficult to build a traditional mathematical model.
                </p>
                <p class="animate-on-scroll">
                    ML models provide the right balance of handling complexity without requiring much heavy lifting from the user's end, while also letting the user decide the architecture for the model. This is why we decided to use ML models for our project.
                </p>
            </section>

            <section id="xgboost" data-aos="fade-up">
                <h2>XGBoost Models</h2>
                <p class="animate-on-scroll">
                    XGBoost models are a type of ensemble model, which combines multiple weak learners to create a strong learner. The weak learners are decision trees (think of decision trees as a series of if-else questions, or as I like to call it: your friend going down a slippery slope fallacy in a lot of parallel universes), which are simple models that can be trained on small datasets. To simplify, a neural network uses layers of neurons, while an XGBoost uses layers of decision trees.
                </p>
                <p class="animate-on-scroll">
                    XGBoost models are less prone to overfitting and can be trained on smaller datasets.
                </p>

                <h3 id="architecture">Architecture</h3>
                <p class="animate-on-scroll">
                    Let us first talk about ammonium. Since that is what we are trying to predict, we have 902 rows and a pretty skewed representation of the amount of ammonium. To address this high skewness, we applied a log(1+x) transformation, which stabilizes variance and improves model learning on positively skewed data.
                </p>
                
                <div class="image-credit-wrapper">
                    <img src="https://static.igem.wiki/teams/6006/wiki/admodelling/unnamed.avif" 
                         alt="Log(1+x) Transformation of Ammonium Data" 
                         class="animate-on-scroll" 
                         style="display: block; margin: 1rem auto 0; max-width: 800px; border-radius: 1rem; box-shadow: 0 10px 15px -3px rgba(0,0,0,0.1); margin-bottom: 2rem;">
                    <p class="image-credit">Figure: Log(1+x) Transformation of Ammonium Data</p>
                </div>

                <p class="animate-on-scroll">
                    We used an XGBoost Regressor with hyperparameters tuned through a previous search. The chosen configuration emphasized balanced learning with moderate regularization:
                </p>

                <div class="table-wrapper">
                    <table class="custom-table">
                        <thead>
                            <tr>
                                <th>Parameter</th>
                                <th>Description</th>
                                <th>Value</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>max_depth</td>
                                <td>Maximum depth of each decision tree. Controls model complexity.</td>
                                <td>7</td>
                            </tr>
                            <tr>
                                <td>n_estimators</td>
                                <td>Number of boosting rounds (trees) used during training.</td>
                                <td>500</td>
                            </tr>
                            <tr>
                                <td>learning_rate</td>
                                <td>Shrinkage step applied after each boosting round to improve generalization.</td>
                                <td>0.01</td>
                            </tr>
                            <tr>
                                <td>colsample_bytree</td>
                                <td>Fraction of features randomly sampled for each tree.</td>
                                <td>0.7</td>
                            </tr>
                            <tr>
                                <td>subsample</td>
                                <td>Fraction of training samples used for growing each tree. Helps reduce overfitting.</td>
                                <td>0.7</td>
                            </tr>
                            <tr>
                                <td>objective</td>
                                <td>Specifies the learning task and loss function. Here, a standard squared error regression is used.</td>
                                <td>reg:squarederror</td>
                            </tr>
                            <tr>
                                <td>random_state</td>
                                <td>Seed for reproducibility.</td>
                                <td>42</td>
                            </tr>
                            <tr>
                                <td>n_jobs</td>
                                <td>Number of parallel threads used during training.</td>
                                <td>-1 (uses all cores)</td>
                            </tr>
                        </tbody>
                    </table>
                </div>

                <p class="animate-on-scroll">
                    Since the model predicts ammonium in log-space, we applied a smearing estimate (a standard bias correction technique) when converting predictions back to the original scale. This improves the accuracy of back-transformed predictions, especially when residuals are not perfectly normally distributed.
                </p>
            </section>
            
            <section id="results" data-aos="fade-up">
                <h2>Results</h2>
                <p class="animate-on-scroll">
                    We evaluated the model on the test set using standard regression metrics on the original ammonium scale:
                </p>

                <div class="table-wrapper">
                    <table class="custom-table">
                        <thead>
                            <tr>
                                <th>Metric</th>
                                <th>Description</th>
                                <th>Value</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>R² Score</td>
                                <td>Proportion of variance in ammonium concentrations explained by the model.</td>
                                <td>0.5924</td>
                            </tr>
                            <tr>
                                <td>RMSE</td>
                                <td>Root Mean Squared Error — measures the model’s prediction error in mg/kg on the original scale.</td>
                                <td>9.37</td>
                            </tr>
                            <tr>
                                <td>MAE</td>
                                <td>Mean Absolute Error — average absolute difference between predicted and actual ammonium values.</td>
                                <td>4.54</td>
                            </tr>
                        </tbody>
                    </table>
                </div>
                
                <div class="image-credit-wrapper">
                    <img src="https://static.igem.wiki/teams/6006/wiki/admodelling/unnamed2.avif" 
                         alt="Prediction vs Reality Graph" 
                         class="animate-on-scroll" 
                         style="display: block; margin: 1rem auto 0; max-width: 800px; border-radius: 1rem; box-shadow: 0 10px 15px -3px rgba(0,0,0,0.1); margin-bottom: 2rem;">
                    <p class="image-credit">Figure: Prediction vs. Reality Graph</p>
                </div>

                <p class="animate-on-scroll">
                    The model’s results are pretty good overall, especially considering how complex and varied the soil data is. Explaining almost 60% of the variation in ammonium levels means the model is picking up on many important patterns, even though it’s not perfect. The error values show that it can give a fairly accurate estimate, but there’s still some natural variability it can’t fully predict — which makes sense given the mix of different soils and conditions in the dataset. In simple terms, the model is reliable enough to guide experiments and highlight key factors, even if it’s not meant for exact field predictions.
                </p>
                <p class="animate-on-scroll">
                    The dataset being quite small, with only 902 samples, likely limits the model's performance.
                </p>
            </section>

            <section id="synthetic-data" data-aos="fade-up">
                <h2>Synthetic Data</h2>
                <p class="animate-on-scroll">
                    We had a small dataset for predicting the ammonium concentration in soil without the presence of our engineered bacteria, but we had no data for predicting ammonium concentration in soil with the presence of our engineered bacteria. This is a huge problem, since we have essentially nothing to go on.
                </p>
                <p class="animate-on-scroll">
                    To solve this, we used synthetic data to augment our dataset. Synthetic data is artificially generated data that mimics the statistical properties of real data.
                </p>
                <p class="animate-on-scroll">
                    We generated synthetic data by simulating the effect of our engineered bacteria on ammonium levels. We assumed that the presence of our bacteria would increase ammonium concentration by a certain percentage, based on literature values and preliminary lab results.
                </p>
                <p class="animate-on-scroll">
                    To estimate the increase factor, we assumed the rate of the entire process to be equal to the rate of the first step– nitrate reduction.
                </p>
                <p class="animate-on-scroll">
                    We used the maximum DNRA rate obtained from our ODE model to estimate the new rate of DNRA.
                </p>
                <p class="animate-on-scroll">
                    We characterized the basal DNRA rate using the Michaelis-Menten kinetics of nitrate reduction of Nap enzyme done by the previous iGEM team – Cattlelyest from Wageningen, 2021.
                </p>
                <p class="animate-on-scroll">
                    By these approximations, we obtained a 10x increase rate. The basal rate of DNRA is given by:
                </p>
                <p class="animate-on-scroll">
                    We then applied this increase to our existing dataset to create a new synthetic dataset that represents soil conditions with our engineered bacteria.
                </p>
            </section>               
              
            <section id="synthetic-data-results" data-aos="fade-up">
                <h2>Results of Synthetic Data Modelling</h2>
                <p class="animate-on-scroll">
                    Mean Predicted Ammonium for the basal level was obtained to 7.39 mg N/kg soil, and after the application of the bacteria was 23.24 mg N/kg soil, which is a predicted increase of 15.86 (+214.74%).
                </p>
            </section>
            

    <section class="references" aria-labelledby="references-heading">
      <h2 id="references-heading">References</h2>
      <ol>
        <li>
          iGEM wiki WUR 2021. “Team:Wageningen UR/Model/Nitrogen - 2021.Igem.org.” Igem.org, 2021, 
          <a href="https://2021.igem.org/Team:Wageningen_UR/Model/Nitrogen" target="_blank">2021.igem.org/Team:Wageningen_UR/Model/Nitrogen</a>
        </li>
      </ol>
    </section>

        </article>
        
    </main>
</div>


    {% endblock %}


{% block scripts %}
<script src="{{ url_for('static', filename='ml.js') }}"></script>
<script src="{{ url_for('static', filename='aos.js') }}"></script>
{% endblock %}